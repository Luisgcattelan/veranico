{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tt = xr.open_dataset('daily_datasets\\chirps\\chirps-v2.0.1981.days_p05.nc')\n",
    "#download https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p05/chirps-v2.0.1981.days_p05.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xavier = xr.open_dataset(r'daily_datasets\\xavier_cerrado_81_20.nc', chunks={'time': 100})\n",
    "xavier_test = xavier.sel(lat=slice(-15, -13), lon=slice(-50, -48))\n",
    "Data = xavier_test.pr.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##now a function that set to 0 the value if the  next day is bigger than the previous\n",
    "#def consecutive(da, thresh=1):\n",
    "#    count = 0\n",
    "#    da = da.squeeze()\n",
    "#    overall_counter = np.zeros(len(da))\n",
    "#    #print(da.shape)\n",
    "#    lenn = len(da) - 1\n",
    "#    for i,j in enumerate(da):\n",
    "#        if i != lenn:\n",
    "#            count = count+1 if da[i] <= thresh else 0\n",
    "#            ddry = count if  da[i+1] >= thresh else 0     \n",
    "#        else:\n",
    "#            count = count+1 if da[i] <= thresh else 0\n",
    "#            ddry = 0\n",
    "#        overall_counter[i] = ddry\n",
    "#    #print('done')\n",
    "#    return overall_counter\n",
    "#\n",
    "#daa = xr.apply_ufunc(\n",
    "#        consecutive, Data,\n",
    "#        input_core_dims=[['time']],  # Specify input dimensions\n",
    "#        output_core_dims=[['new_time']],  # Specify output dimensions\n",
    "#        kwargs={'thresh': 1},  # Additional arguments\n",
    "#        dask='parallelized',  # Enable dask\n",
    "#        vectorize=True, \n",
    "#        #output_dtypes=[float],\n",
    "#    )\n",
    "#\n",
    "#daa = daa.rename({\"new_time\": \"time\"})\n",
    "#daa[\"time\"] = Data.time.values\n",
    "#daa = daa.rename('CDD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now speed up with numba\n",
    "from numba import float64, guvectorize\n",
    "\n",
    "@guvectorize([(float64[:] , float64[:])], '(n) -> (n)')\n",
    "def consecutive_numba(da, out):\n",
    "    count = 0\n",
    "    lenn = len(da) - 1\n",
    "    overall_counter = np.zeros(len(da))\n",
    "    for i,j in enumerate(da):\n",
    "        if i != lenn:\n",
    "            count = count+1 if da[i] <= 1 else 0\n",
    "            ddry = count if  da[i+1] >= 1 else 0     \n",
    "        else:\n",
    "            count = count+1 if da[i] <= 1 else 0\n",
    "            ddry = 0\n",
    "        overall_counter[i] = ddry\n",
    "    out[:] = overall_counter\n",
    "    #print('ddry done')\n",
    "    #return out\n",
    "\n",
    "#create a function to apply the xr.apply_ufunc and to rename the output\n",
    "def cdd_numba(da):\n",
    "    daa = xr.apply_ufunc(\n",
    "        consecutive_numba, da.chunk({'time': -1, 'lat': 20, 'lon': 20}),\n",
    "        input_core_dims=[['time']],  # Specify input dimensions\n",
    "        output_core_dims=[['new_time']],  # Specify output dimensions\n",
    "        #kwargs={'thresh': 1},  # Additional arguments\n",
    "        dask='parallelized',  # Enable dask\n",
    "        #vectorize=True, \n",
    "        #output_dtypes=[float],\n",
    "        output_sizes={'new_time': len(da.time)}\n",
    "    )\n",
    "    daa = daa.rename({\"new_time\": \"time\"})\n",
    "    daa[\"time\"] = da.time.values\n",
    "    daa = daa.rename('CDD')\n",
    "    return daa.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisg\\AppData\\Local\\Temp\\ipykernel_2592\\2608764309.py:23: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  daa = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "aaa = cdd_numba(xavier.pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
